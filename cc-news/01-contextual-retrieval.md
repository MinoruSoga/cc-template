# コンテキストエンジニアリング

> 出典: [Effective Context Engineering for AI Agents](https://www.anthropic.com/engineering/effective-context-engineering-for-ai-agents), [Introducing Contextual Retrieval](https://www.anthropic.com/engineering/contextual-retrieval)

## 概要

コンテキストエンジニアリングは、単にプロンプトを改善するのではなく、LLM推論時に「最適なトークンセット」を戦略的に管理することに焦点を当てた手法です。ループで動作するエージェントは拡大するデータを生成し、それを周期的に精製する必要があります。

## コンテキストエンジニアリングの重要性

### コンテキストロット問題

「needle-in-a-haystack」ベンチマーキング研究により、**コンテキストロット**が明らかになりました：

- トークンが増加するとモデルの想起精度が低下
- Transformerアーキテクチャのn²ペアワイズトークン関係がコンテキストサイズと注意集中の間に固有の緊張を生む

### 基本原則

> 「望む結果の可能性を最大化する、最小の高信号トークンセットを見つける」

## 主要なテクニック

### 1. システムプロンプト

**バランスが重要**：
- 過度に厳格（脆いif-elseロジック）を避ける
- 曖昧すぎるガイダンスを避ける
- 「明確で直接的な言語」を適切な抽象度で使用

```markdown
# 良い例
ユーザーの質問に簡潔に回答してください。
技術的な詳細が必要な場合は、段階的に説明してください。

# 悪い例（過度に厳格）
質問が技術的な場合、必ず3つのステップで回答。
質問が一般的な場合、1文で回答。
```

### 2. ツール設計

**原則**：
- 最小限で重複しないツールセットを設計
- 曖昧さを排除
- ユーザーもエージェントもどのツールを適用すべきか明確に識別できるように

### 3. ジャストインタイム検索

事前にすべてのデータを読み込むのではなく：

1. 軽量な識別子（ファイルパス、URL）を維持
2. ツールを通じて動的にコンテンツをロード
3. 人間の認知を模倣

```
従来: 全データをコンテキストに読み込む → 処理
JIT: 識別子のみ保持 → 必要時にツールで取得 → 処理
```

## 長時間ホライズン戦略

### コンパクション（圧縮）

- コンテキストを要約してリセット
- 重要なアーキテクチャ決定は保持
- 古い詳細は省略

### 構造化ノートテイキング

- エージェントが外部メモリファイルを維持
- 永続的な知識を保存
- セッション間での情報継続

### サブエージェントアーキテクチャ

- 専門化されたエージェントが集中したタスクを処理
- 凝縮されたサマリーを返す
- 各エージェントが独自のコンテキストウィンドウを持つ

---

# Contextual Retrieval（文脈的検索）

## 概要

Contextual Retrievalは、ドキュメントチャンクを埋め込む前にコンテキストを追加することで、情報検索を劇的に改善する手法です。検索失敗を**49%削減**、リランキングと組み合わせると**67%削減**を実現します。

## 従来のRAGの問題

従来のRAGシステムは、ドキュメントをエンコードする際に重要なコンテキストを除去します。

**例**：
- チャンク：「収益は3%増加しました」
- **失われる情報**：どの会社か？いつの期間か？

## 主要イノベーション

### Contextual Embeddings

チャンクをベクトル埋め込み作成前に説明的コンテキストで前置：

```
【従来】
「収益は3%増加しました」

【Contextual】
「このチャンクはACME社の2023年Q2業績に関するSEC提出書類からです。
前四半期の収益は3億1400万ドルでした。
収益は3%増加しました」
```

### Contextual BM25

同じコンテキスト付加を字句マッチングにも適用し、完全一致検索とセマンティック理解を組み合わせます。

## 実装手順

### ステップ1: コンテキスト生成

```python
# Claude 3 Haikuを使用して各チャンクに
# 50-100トークンのコンテキストサマリーを生成
def generate_context(document, chunk):
    prompt = f"""
    以下のドキュメント全体を考慮して、
    このチャンクに文脈を提供する短い説明を生成してください。

    ドキュメント: {document[:1000]}...
    チャンク: {chunk}
    """
    return claude.generate(prompt)
```

### ステップ2: 埋め込みとインデックス

```python
contextualized_chunk = context + original_chunk
embedding = embed(contextualized_chunk)
index.add(embedding)
```

### ステップ3: コスト最適化

- プロンプトキャッシングを活用
- コストを約**$1.02/100万ドキュメントトークン**に削減

## パフォーマンス結果

| 手法 | 失敗率削減 |
|------|-----------|
| Contextual Embeddings単独 | 35%（5.7% → 3.7%） |
| + BM25 | 49%（5.7% → 2.9%） |
| + リランキング | 67%（5.7% → 1.9%） |

## ベストプラクティス

1. **Top-20チャンクを取得**（5や10より効果的）
2. **GeminiまたはVoyage埋め込み**を使用して最適な結果を得る
3. **ドメイン固有のプロンプトを調整**
4. **チャンクサイズ、境界、オーバーラップを慎重に検討**
5. **特定のユースケースで常に評価**

## 実装リソース

AnthropicのGitHub Cookbookで実装例が利用可能です。
