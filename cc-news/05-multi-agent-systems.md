# マルチエージェントリサーチシステム

> 出典: [How We Built Our Multi-Agent Research System](https://www.anthropic.com/engineering/multi-agent-research-system)

## 概要

Anthropicは、Claudeが複雑なリサーチを実行できる洗練されたマルチエージェントアーキテクチャを構築しました。このシステムは、リードエージェントが複数のサブエージェントを調整し、それぞれが異なる側面を同時に探索します。

## コアアーキテクチャ

### オーケストレーター・ワーカーパターン

```
┌─────────────────┐
│   リードエージェント    │
│   (Claude Opus 4)      │
└─────────┬───────┘
          │
    ┌─────┴─────┐
    ↓           ↓           ↓
┌───────┐ ┌───────┐ ┌───────┐
│サブA  │ │サブB  │ │サブC  │
│(Sonnet)│ │(Sonnet)│ │(Sonnet)│
└───────┘ └───────┘ └───────┘
    │           │           │
    └─────┬─────┘
          ↓
    ┌───────────┐
    │引用エージェント│
    └───────────┘
```

### 役割分担

| エージェント | 役割 |
|--------------|------|
| リードエージェント | クエリ分析、戦略開発、サブエージェント生成 |
| サブエージェント | 独立したコンテキストウィンドウで並列検索 |
| 引用エージェント | 発見の処理と適切なソース帰属の確保 |

## 主要なパフォーマンス洞察

### トークン使用量と品質の関係

> 「トークン使用量だけでリサーチ品質の分散の80%を説明する」

### パフォーマンス比較

| 構成 | 結果 |
|------|------|
| シングルエージェント（Opus） | ベースライン |
| マルチエージェント（Opus + Sonnet） | **90.2%向上** |

### コスト・ベネフィット

| モード | トークン消費 |
|--------|-------------|
| チャット | 1x |
| エージェント | ~4x |
| マルチエージェント | ~15x |

高価値タスクでのみ増加したトークン支出を正当化できます。

## 8つのプロンプティング原則

### 原則1: エージェントのように考える

エージェントの動作をシミュレートして失敗モードを特定：

```
「このクエリでエージェントはどのように動作するか？」
「どこで行き詰まる可能性があるか？」
```

### 原則2: 委任を教える

明示的なタスク境界と出力形式を提供：

```markdown
## サブエージェントへの指示
- 検索範囲: [具体的なトピック]
- 期待される出力形式: [構造化データ]
- 完了条件: [明確な基準]
```

### 原則3: 複雑さに応じて努力をスケール

クエリの難易度にリソースを一致させるルールを埋め込む：

```
シンプルなクエリ → 1-2サブエージェント
中程度のクエリ → 3-5サブエージェント
複雑なクエリ → 5+サブエージェント
```

### 原則4: ツール設計が重要

明確な説明とヒューリスティクスで誤ったツール選択を防止：

```json
{
  "name": "web_search",
  "description": "一般的なWeb検索。学術論文には academic_search を使用",
  "when_to_use": "現在のイベント、一般情報"
}
```

### 原則5: エージェントに自己改善させる

Claudeを使用してエージェントの失敗を診断・修正：

```
「この失敗したリサーチを分析して、改善点を提案して」
```

### 原則6: 広く始めて、絞り込む

人間のリサーチ方法論を模倣：

```
1. 広範な探索検索
2. 関連領域の特定
3. 深掘り調査
4. 結果の統合
```

### 原則7: 思考をガイド

- **拡張思考**: 計画に活用
- **インターリーブ思考**: 評価に活用

### 原則8: 積極的に並列化

同時ツール呼び出しでリサーチ時間を**90%削減**：

```python
# 並列実行
results = await asyncio.gather(
    search_source_a(query),
    search_source_b(query),
    search_source_c(query)
)
```

## 評価戦略

### 初期評価

- 小さなサンプル（~20テストケース）から開始
- 初期段階で劇的な改善を示す

### LLMジャッジ

単一のルーブリックで以下を評価：
- 精度
- 引用
- 完全性
- ソース品質
- 効率性

### 人間評価の重要性

自動化が見逃すバイアスを人間評価が捕捉：
- SEO最適化コンテンツの優先
- 表面的な関連性vs実質的な価値

## 本番環境での課題

### ステートフルネス

```
課題: エージェントが拡張セッション全体でコンテキストを維持
解決: 失敗後の再開をサポート（完全再起動ではなく）
```

### デバッグ

```
課題: 非決定論的な動作
解決: 会話内容にアクセスせずに決定パターンを監視する
      本番トレーシング
```

### デプロイメント

```
課題: アクティブエージェントへの中断防止
解決: レインボーデプロイメント
      - バージョン間でトラフィックを徐々にシフト
```

### 同期ボトルネック

```
課題: 現在の逐次サブエージェント実行が調整制限を作成
将来: 非同期アプローチで改善可能
```

## 実世界での影響

ユーザーは以下を報告：
- 見落とされていたビジネス機会の発見
- 複雑な意思決定のナビゲーション
- **数日分のリサーチ作業の節約**

### トップユースケース

| 用途 | 割合 |
|------|------|
| 専門ソフトウェア開発 | 10% |
| プロフェッショナルコンテンツ最適化 | 8% |
| ビジネス戦略リサーチ | 8% |

## 実装のベストプラクティス

### アーキテクチャ設計

```python
class MultiAgentResearchSystem:
    def __init__(self):
        self.lead_agent = ClaudeOpus4()
        self.subagent_pool = [ClaudeSonnet4() for _ in range(5)]
        self.citation_agent = CitationProcessor()

    async def research(self, query: str):
        # 1. 戦略策定
        strategy = await self.lead_agent.plan(query)

        # 2. 並列検索
        tasks = [
            self.subagent_pool[i].search(topic)
            for i, topic in enumerate(strategy.topics)
        ]
        results = await asyncio.gather(*tasks)

        # 3. 統合と引用
        return await self.citation_agent.process(results)
```

### リソース管理

- サブエージェント数を動的に調整
- トークン予算を設定
- タイムアウトを実装

### 品質保証

- 各ステップで中間結果を検証
- 失敗したサブエージェントを再試行
- 最終結果を引用エージェントで検証
